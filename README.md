# The application implements a Retrieval-Augmented Generation (RAG) pipeline that processes PDF documents, extracts relevant information, and answers user queries using an LLM (Large Language Model). 

How to set up DeepSeek R1 on your local machine to securely query PDF documents using retrieval-augmented generation (RAG), from downloading and configuring the model with Ollama to building a Gradio-based web app that processes PDF files using LangChain and vector databases. Whether you’re on a Mac or Windows, this video covers data preprocessing, text embedding, and semantic search, giving you a comprehensive understanding of local AI-assisted document queries without any reliance on the cloud.

![image](https://github.com/user-attachments/assets/2082e8fb-7bb8-4b41-a9b4-40b0307cace4)

![image](https://github.com/user-attachments/assets/3de49bea-f387-477b-983a-2660dff8ca05)

![image](https://github.com/user-attachments/assets/41651cf9-e30d-4265-8961-d72cd7a673a2)

project details can be found in this link: https://bit.ly/4hpF3du — You may need to sign up (for free!) to DataLab

https://youtu.be/hOsZzcMYMLI
